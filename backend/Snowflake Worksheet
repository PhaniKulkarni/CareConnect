CREATE DATABASE IF NOT EXISTS Medical_CORTEX_SEARCH_app;
CREATE SCHEMA IF NOT EXISTS Medical_CORTEX_SEARCH_app.DATA;


create function if not exists MEDICAL_CORTEX_SEARCH_APP.DATA.DOCS_CHUNKS_TABLEtext_chunker(pdf_text string)
returns table (chunk varchar)
language python
runtime_version = '3.9'
handler = 'text_chunker'
packages = ('snowflake-snowpark-python', 'langchain')
as
$$
from snowflake.snowpark.types import StringType, StructField, StructType
from langchain.text_splitter import RecursiveCharacterTextSplitter
import pandas as pd

class text_chunker:

    def process(self, pdf_text: str):
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size = 1512, #Adjust this as you see fit
            chunk_overlap  = 256, #This let's text have some form of overlap. Useful for keeping chunks contextual
            length_function = len
        )
    
        chunks = text_splitter.split_text(pdf_text)
        df = pd.DataFrame(chunks, columns=['chunks'])
        
        yield from df.itertuples(index=False, name=None)
$$;


create  stage if not exists docs ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE') DIRECTORY = ( ENABLE = true );


ls @docs;

create TABLE  if not exists DOCS_CHUNKS_TABLE ( 
    RELATIVE_PATH VARCHAR(16777216), 
    SIZE NUMBER(38,0),
    FILE_URL VARCHAR(16777216),
    SCOPED_FILE_URL VARCHAR(16777216),
    CHUNK VARCHAR(16777216),
    CATEGORY VARCHAR(16777216) 
);
insert into docs_chunks_table (relative_path, size, file_url,
                            scoped_file_url, chunk)

    select relative_path, 
            size,
            file_url, 
            build_scoped_file_url(@docs, relative_path) as scoped_file_url,
            func.chunk as chunk
    from 
        directory(@docs),
        TABLE(DOCS_CHUNKS_TABLEtext_chunker(TO_VARCHAR(SNOWFLAKE.CORTEX.PARSE_DOCUMENT(@docs, 
                              relative_path, {'mode': 'LAYOUT'})))) as func;



CREATE
 TEMPORARY TABLE if not exists docs_categories AS WITH unique_documents AS (
  SELECT
    DISTINCT relative_path
  FROM
    docs_chunks_table
),
docs_category_cte AS (
  SELECT
    relative_path,
    TRIM(snowflake.cortex.COMPLETE (
      'mistral-large',
      'Given the name of the file between <file> and </file> determine if it is related to bikes or snow. Use only one word <file> ' || relative_path || '</file>'
    ), '\n') AS category
  FROM
    unique_documents
)
SELECT
  *
FROM
  docs_category_cte;


select category from docs_categories group by category;


select * from docs_categories;

update docs_chunks_table 
  SET category = docs_categories.category
  from docs_categories
  where  docs_chunks_table.relative_path = docs_categories.relative_path;

CREATE OR REPLACE PROCEDURE PROCESS_UPLOADED_FILE(file_name STRING)
RETURNS STRING
LANGUAGE SQL
AS $$
BEGIN
    INSERT INTO DOCS_CHUNKS_TABLE (relative_path, size, file_url, scoped_file_url, chunk)
    SELECT relative_path, 
           size,
           file_url, 
           build_scoped_file_url(@docs, relative_path) AS scoped_file_url,
           func.chunk AS chunk
    FROM 
        DIRECTORY(@docs),
        TABLE(DOCS_CHUNKS_TABLEtext_chunker(TO_VARCHAR(SNOWFLAKE.CORTEX.PARSE_DOCUMENT(@docs, 
                              relative_path, {'mode': 'LAYOUT'})))) AS func WHERE relative_path = :file_name;
    RETURN 'File Processed Successfully';
END;
$$;



create  CORTEX SEARCH SERVICE if not exists CC_SEARCH_SERVICE_CS
ON chunk
ATTRIBUTES category
warehouse = COMPUTE_WH
TARGET_LAG = '1 minute'
as (
    select chunk,
        relative_path,
        file_url,
        category
    from docs_chunks_table
);


truncate table docs_chunks_table;
